{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 Dataset Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fixed acidity</th>\n",
       "      <td>8.311111</td>\n",
       "      <td>1.747595</td>\n",
       "      <td>4.60000</td>\n",
       "      <td>15.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volatile acidity</th>\n",
       "      <td>0.531339</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>1.58000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citric acid</th>\n",
       "      <td>0.268364</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>residual sugar</th>\n",
       "      <td>2.532152</td>\n",
       "      <td>1.355917</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>15.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorides</th>\n",
       "      <td>0.086933</td>\n",
       "      <td>0.047267</td>\n",
       "      <td>0.01200</td>\n",
       "      <td>0.61100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <td>15.615486</td>\n",
       "      <td>10.250486</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>68.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <td>45.914698</td>\n",
       "      <td>32.782130</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>289.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.996730</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.99007</td>\n",
       "      <td>1.00369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>3.311015</td>\n",
       "      <td>0.156664</td>\n",
       "      <td>2.74000</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulphates</th>\n",
       "      <td>0.657708</td>\n",
       "      <td>0.170399</td>\n",
       "      <td>0.33000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alcohol</th>\n",
       "      <td>10.442111</td>\n",
       "      <td>1.082196</td>\n",
       "      <td>8.40000</td>\n",
       "      <td>14.90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>5.657043</td>\n",
       "      <td>0.805824</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean        std      min        max\n",
       "fixed acidity          8.311111   1.747595  4.60000   15.90000\n",
       "volatile acidity       0.531339   0.179633  0.12000    1.58000\n",
       "citric acid            0.268364   0.196686  0.00000    1.00000\n",
       "residual sugar         2.532152   1.355917  0.90000   15.50000\n",
       "chlorides              0.086933   0.047267  0.01200    0.61100\n",
       "free sulfur dioxide   15.615486  10.250486  1.00000   68.00000\n",
       "total sulfur dioxide  45.914698  32.782130  6.00000  289.00000\n",
       "density                0.996730   0.001925  0.99007    1.00369\n",
       "pH                     3.311015   0.156664  2.74000    4.01000\n",
       "sulphates              0.657708   0.170399  0.33000    2.00000\n",
       "alcohol               10.442111   1.082196  8.40000   14.90000\n",
       "quality                5.657043   0.805824  3.00000    8.00000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.read_csv('WineQT.csv')\n",
    "df = df.drop(columns=['Id'])\n",
    "\n",
    "# Describe the dataset\n",
    "description = {\n",
    "  'mean': df.mean(),\n",
    "  'std': df.std(),\n",
    "  'min': df.min(),\n",
    "  'max': df.max()\n",
    "}\n",
    "\n",
    "description = pd.DataFrame(description)\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Plot showing distribution of various labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of labels\n",
    "df['quality'].value_counts().sort_index().plot(kind='bar', color='skyblue')\n",
    "plt.xlabel('Quality')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Wine Quality Labels')\n",
    "plt.xticks(rotation='horizontal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['quality'])  # Features\n",
    "y = df['quality']  # Labels\n",
    "\n",
    "# Handle missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')  # You can choose 'mean', 'median', or 'most_frequent'\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Normalize the data using MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# one hot encode y\n",
    "y = np.eye(np.unique(y).shape[0])[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "# 70% for training, 15% for validation, and 15% for testing\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Multinomial Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialLogisticRegression:\n",
    "  def __init__(self, learning_rate=0.01, epochs=10000):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.epochs = epochs\n",
    "    self.losses = []\n",
    "    self.accuracies = []\n",
    "\n",
    "  def _softmax(self, X):\n",
    "    exp_X = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
    "    return exp_X / np.sum(exp_X, axis=1, keepdims=True)\n",
    "\n",
    "  def _cross_entropy_loss(self, y_true, y_pred):\n",
    "    # epsilon = 1e-15\n",
    "    # y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    N = len(y_true)\n",
    "    loss = -np.sum(y_true * np.log(y_pred)) / N\n",
    "    return loss\n",
    "\n",
    "  def train(self, X_train, y_train, X_val, y_val):\n",
    "    num_samples, num_features = X_train.shape\n",
    "    num_classes = len(y_train[0])\n",
    "    self.weights = np.random.rand(num_classes, num_features)\n",
    "\n",
    "    for epoch in range(self.epochs):\n",
    "      scores = np.dot(X_train, self.weights.T)\n",
    "      probabilities = self._softmax(scores)\n",
    "\n",
    "      # Compute cross-entropy loss on training set\n",
    "      loss = self._cross_entropy_loss(y_train, probabilities)\n",
    "      self.losses.append(loss)\n",
    "\n",
    "      # Compute accuracy on training set\n",
    "      y_pred_train = label_encoder.inverse_transform(np.argmax(probabilities, axis=1))\n",
    "      accuracy_train = np.mean(y_pred_train == label_encoder.inverse_transform(np.argmax(y_train, axis = 1)))\n",
    "      self.accuracies.append(accuracy_train)\n",
    "\n",
    "      # Compute probabilities on validation set\n",
    "      scores_val = np.dot(X_val, self.weights.T)\n",
    "      probabilities_val = self._softmax(scores_val)\n",
    "      y_pred_val = label_encoder.inverse_transform(np.argmax(probabilities_val, axis=1))\n",
    "\n",
    "      # Compute accuracy on validation set\n",
    "      accuracy_val = np.mean(y_pred_val == label_encoder.inverse_transform(np.argmax(y_val, axis = 1)))\n",
    "\n",
    "      # Print metrics for this epoch\n",
    "      if epoch == 999:\n",
    "        print(f\"Epoch {epoch + 1}/{self.epochs} - Loss: {loss:.4f} - Accuracy (Train): {accuracy_train:.4f} - Accuracy (Validation): {accuracy_val:.4f}\")\n",
    "\n",
    "      # Update weights using gradient descent\n",
    "      error = probabilities - y_train\n",
    "      gradient = np.dot(X_train.T, error) / num_samples\n",
    "      self.weights -= self.learning_rate * gradient.T\n",
    "      \n",
    "    print(\"Training complete!\")\n",
    "    # print loss and accuracy on train data set\n",
    "    print(\"\\nLoss and Accuracy on Train Set:\")\n",
    "    y_pred_train = self.predict(X_train)\n",
    "    print(\"Loss: \", self._cross_entropy_loss(y_train, y_pred_train))\n",
    "    y_pred_train = np.argmax(y_pred_train, axis = 1)\n",
    "    print(\"Accuracy: \", np.mean(y_pred_train == np.argmax(y_train, axis = 1)))\n",
    "    print()\n",
    "\n",
    "    # Print classification report on validation set after training\n",
    "    self.print_classification_report(X_val, y_val, \"Validation\")\n",
    "    return self.losses, self.accuracies\n",
    "  \n",
    "  def print_classification_report(self, X, y, name=\"Validation\"):\n",
    "    print(f\"Classification Report on {name} Set:\")\n",
    "    y_pred = np.argmax(self.predict(X), axis = 1)\n",
    "    print(classification_report(\n",
    "      label_encoder.inverse_transform(y_pred), \n",
    "      label_encoder.inverse_transform(np.argmax(y, axis = 1)),\n",
    "      zero_division=1\n",
    "      )\n",
    "    )\n",
    "\n",
    "  def predict(self, X):\n",
    "    scores = np.dot(X, self.weights.T)\n",
    "    probabilities = self._softmax(scores)\n",
    "    return probabilities\n",
    "\n",
    "  def evaluate_accuracy(self, X, y):\n",
    "    y_pred = np.argmax(self.predict(X), axis = 1)\n",
    "    accuracy = np.mean(y_pred == np.argmax(y, axis = 1))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000 - Loss: 1.4739 - Accuracy (Train): 0.4913 - Accuracy (Validation): 0.4912\n",
      "Training complete!\n",
      "\n",
      "Loss and Accuracy on Train Set:\n",
      "Loss:  1.4738378513658932\n",
      "Accuracy:  0.49125\n",
      "\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         9\n",
      "           4       0.33      0.17      0.22         6\n",
      "           5       0.81      0.62      0.70        80\n",
      "           6       0.15      0.67      0.24        18\n",
      "           7       0.88      0.36      0.51        58\n",
      "           8       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49       171\n",
      "   macro avg       0.53      0.47      0.28       171\n",
      "weighted avg       0.75      0.49      0.54       171\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mlr = MultinomialLogisticRegression(learning_rate=0.01, epochs=1000)\n",
    "mlr.train(X_train, y_train, X_val, y_val)\n",
    "print('--' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 Hyperparameter tuning and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "  'method': 'grid',\n",
    "  'metric': {\n",
    "    'name': 'composite_metric',\n",
    "    'goal': 'maximize'\n",
    "  },\n",
    "  'parameters': {\n",
    "    'learning_rates': {'values': [0.001, 0.01, 0.1, 1]},\n",
    "    'epochs': {'values': [100, 500, 1000, 2000]}\n",
    "  }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep=sweep_config, project=\"Multinomial-Logistic-Regression\")\n",
    "\n",
    "# Define sweep function\n",
    "def sweep_function():\n",
    "  with wandb.init(config=sweep_config):\n",
    "    learning_rate = wandb.config.learning_rates\n",
    "    epochs = wandb.config.epochs\n",
    "    mlr = MultinomialLogisticRegression(learning_rate=learning_rate, epochs=epochs)\n",
    "    train_losses, train_accuracies = mlr.train(X_train, y_train, X_val, y_val)\n",
    "    validation_loss = mlr._cross_entropy_loss(y_val, mlr.predict(X_val))\n",
    "    validation_accuracy = mlr.evaluate_accuracy(X_val, y_val)\n",
    "    \n",
    "    # Log hyperparameters and validation loss\n",
    "    wandb.log({\n",
    "      \"learning_rate\": learning_rate, \n",
    "      \"epochs\": epochs, \n",
    "      \"validation_loss\": validation_loss, \n",
    "      \"validation_accuracy\": validation_accuracy, \n",
    "      \"composite_metric\": validation_accuracy - 0.2 * validation_loss\n",
    "    })\n",
    "    epochs = np.arange(1, len(train_losses) + 1)\n",
    "    \n",
    "    for i in range(1, len(train_losses) + 1):\n",
    "      wandb.log({\n",
    "        \"epoch\": i,\n",
    "        \"train_loss\": train_losses[i-1],\n",
    "        \"train_accuracy\": train_accuracies[i-1]\n",
    "      })\n",
    "      \n",
    "wandb.agent(sweep_id, function=sweep_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wandb logging done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sorting runs by -summary_metrics.composite_metric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for best run:\n",
      "epochs: 1000 \n",
      "learning_rate: 0.1 \n",
      "validation_loss: 1.5133413349674043 \n",
      "validation_accuracy: 0.5555555555555556 \n",
      "composite_metric: -0.20111511192814657\n"
     ]
    }
   ],
   "source": [
    "# Initialize W&B API\n",
    "api = wandb.Api()\n",
    "\n",
    "best_run = api.sweep(\"chnaveenin/Multinomial-Logistic-Regression/sweeps/\"+sweep_id).best_run()\n",
    "print('Results for best run:')\n",
    "print(\n",
    "  'epochs:', best_run.config['epochs'], '\\n'\n",
    "  'learning_rate:', best_run.config['learning_rates'], '\\n'\n",
    "  'validation_loss:', best_run.summary['validation_loss'], '\\n'\n",
    "  'validation_accuracy:', best_run.summary['validation_accuracy'], '\\n'\n",
    "  'composite_metric:', best_run.summary['composite_metric'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000 - Loss: 1.3968 - Accuracy (Train): 0.5800 - Accuracy (Validation): 0.5497\n",
      "Training complete!\n",
      "\n",
      "Loss and Accuracy on Train Set:\n",
      "Loss:  1.3968425713674464\n",
      "Accuracy:  0.58\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         2\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.74      0.61      0.67        75\n",
      "           6       0.40      0.65      0.49        49\n",
      "           7       0.67      0.42      0.52        38\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.55       171\n",
      "   macro avg       0.47      0.28      0.28       171\n",
      "weighted avg       0.60      0.55      0.55       171\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Accuracy (Test): 0.5523255813953488\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.74      0.71      0.72        85\n",
      "           6       0.38      0.54      0.45        46\n",
      "           7       0.59      0.30      0.40        33\n",
      "           8       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.55       172\n",
      "   macro avg       0.45      0.26      0.26       172\n",
      "weighted avg       0.59      0.55      0.55       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlr = MultinomialLogisticRegression(learning_rate=best_run.config['learning_rates'], epochs=best_run.config['epochs'])\n",
    "mlr.train(X_train, y_train, X_val, y_val)\n",
    "print('--'*50)\n",
    "print()\n",
    "print('Accuracy (Test):', mlr.evaluate_accuracy(X_test, y_test))\n",
    "mlr.print_classification_report(X_test, y_test, \"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
